{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unzip and read turns files into pandas df\n",
    "zf1 = zipfile.ZipFile('./data_and_etl//turns_part1.zip') \n",
    "turns1 = pd.read_csv(zf1.open('turns_part1.csv'), encoding='utf-8')\n",
    "zf2 = zipfile.ZipFile('./data_and_etl//turns_part2.zip') \n",
    "turns2 = pd.read_csv(zf2.open('turns_part2.csv'), encoding='utf-8')\n",
    "zf3 = zipfile.ZipFile('./data_and_etl//turns_part3.zip') \n",
    "turns3 = pd.read_csv(zf3.open('turns_part3.csv'), encoding='utf-8')\n",
    "zf4 = zipfile.ZipFile('./data_and_etl//turns_part4.zip') \n",
    "turns4 = pd.read_csv(zf4.open('turns_part4.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdict extraction done!\n",
      "Advocate side extraction done!\n",
      "Data re-shaping and combining done!\n"
     ]
    }
   ],
   "source": [
    "###Setup Data\n",
    "\n",
    "#use original scdb winning party as verdict\n",
    "#verdict value 0 = no favorable disposition for petitioning part apparent\n",
    "#verdict value 1 = petitioning party received a favorable disposition\n",
    "verdict = []\n",
    "verdict_csv = csv.reader(open('./data_and_etl//SCDB_2017_01_caseCentered_Citation.csv'))\n",
    "for row in verdict_csv:\n",
    "    docket_number = re.sub('-', '_', row[13])\n",
    "    docket_number = re.sub(' ORIG', '_orig', docket_number)\n",
    "    case_id = row[10]+'_'+docket_number\n",
    "    verdict.append([case_id, row[12], row[17], row[19], row[36], row[39], row[40]])\n",
    "    \n",
    "verdict_header = verdict.pop(0)\n",
    "verdict = pd.DataFrame(verdict, columns = verdict_header)\n",
    "    \n",
    "print \"Verdict extraction done!\"\n",
    "    \n",
    "#concate the turns files\n",
    "turns_combined = pd.concat([turns1, turns2, turns3, turns4])\n",
    "\n",
    "#remove _t01 and _t02 from transcript_id in turns_combined\n",
    "turns_combined['transcript_id'] = turns_combined['transcript_id'].str.replace('_t01','')\n",
    "turns_combined['transcript_id'] = turns_combined['transcript_id'].str.replace('_t02','')\n",
    "\n",
    "#get advocate sides\n",
    "advocates = pd.read_json('./advocate_dict.json')\n",
    "\n",
    "advocate_turns = []\n",
    "\n",
    "for index, row in turns_combined.iterrows():\n",
    "    if row['speaker_role'] == 'scotus_justice':\n",
    "        advocate_turns.append('scotus_justice')\n",
    "    else:\n",
    "        speaker = row['speaker']\n",
    "        transcript_id = row['transcript_id']\n",
    "        try:\n",
    "            lawyer_side = advocates.ix[speaker][transcript_id]\n",
    "            advocate_turns.append(lawyer_side)\n",
    "        except:\n",
    "            advocate_turns.append('None')\n",
    "\n",
    "#insert advocate side to the turns_combined dataframe\n",
    "turns_combined['lawyer_side'] = advocate_turns\n",
    "\n",
    "\n",
    "#create speaking length column\n",
    "turns_combined = turns_combined.assign(speaking_length = lambda x: x.text_stop - x.text_start)\n",
    "turns_combined.loc[turns_combined['speaking_length'] < 0, 'speaking_length'] = 1\n",
    "\n",
    "print \"Advocate side extraction done!\"\n",
    "\n",
    "#pivot turns files by transcript_id and lawyer_side for texts\n",
    "lawyer_side_text_pivot = turns_combined.pivot_table(index = 'transcript_id', \n",
    "                                                     columns = 'lawyer_side', \n",
    "                                                     values = 'text',\n",
    "                                                     aggfunc=lambda x: ' '.join(x))\n",
    "#reset index\n",
    "lawyer_side_text_pivot = lawyer_side_text_pivot.reset_index()\n",
    "\n",
    "#drop columns with no lawyer side tags\n",
    "lawyer_side_text_pivot = lawyer_side_text_pivot.drop(['NEED MORE INFO', 'None'], axis = 1)\n",
    "\n",
    "#count of number of times speaker spoke\n",
    "counts_pivot = pd.pivot_table(turns_combined[['transcript_id', 'lawyer_side']],\n",
    "                              index = 'transcript_id',\n",
    "                              columns = 'lawyer_side',\n",
    "                              aggfunc=len,\n",
    "                              fill_value=0)\n",
    "\n",
    "#reset index\n",
    "counts_pivot = counts_pivot.reset_index()\n",
    "\n",
    "#drop columns with no lawyer side tags\n",
    "counts_pivot = counts_pivot.drop(['NEED MORE INFO', 'None'], axis = 1)\n",
    "\n",
    "#rename headers\n",
    "counts_pivot.columns = ['transcript_id', 'appellant/petitioner_count', 'appellee/respondent_count',\n",
    "                       'scotus_justice_count']\n",
    "\n",
    "#length of speaker speaking\n",
    "length_pivot = pd.pivot_table(turns_combined[['transcript_id', 'speaking_length', 'lawyer_side']],\n",
    "                              index = 'transcript_id',\n",
    "                              columns = 'lawyer_side',\n",
    "                              values = 'speaking_length',\n",
    "                              aggfunc=np.sum,\n",
    "                              fill_value=0)\n",
    "\n",
    "#reset index\n",
    "length_pivot = length_pivot.reset_index()\n",
    "\n",
    "#drop columns with no lawyer side tags\n",
    "length_pivot = length_pivot.drop(['NEED MORE INFO', 'None'], axis = 1)\n",
    "\n",
    "#rename headers\n",
    "length_pivot.columns = ['transcript_id', 'appellant/petitioner_length', 'appellee/respondent_length',\n",
    "                       'scotus_justice_length']\n",
    "\n",
    "#pivot turns files by transcript_id and speaker_role for texts\n",
    "speaker_role_text_pivot = turns_combined.pivot_table(index = 'transcript_id', \n",
    "                                                     columns = 'speaker_role', \n",
    "                                                     values = 'text',\n",
    "                                                     aggfunc=lambda x: ' '.join(x))\n",
    "\n",
    "#reset index\n",
    "speaker_role_text_pivot = speaker_role_text_pivot.reset_index()\n",
    "\n",
    "#concatenate pivots together\n",
    "pivots_concate = pd.concat([lawyer_side_text_pivot,\n",
    "                            counts_pivot[counts_pivot.columns[1:4]], \n",
    "                            length_pivot[length_pivot.columns[1:4]],\n",
    "                            speaker_role_text_pivot[speaker_role_text_pivot.columns[1]]],\n",
    "                            axis=1,\n",
    "                            join='inner')\n",
    "\n",
    "#Convert feature attributes to ints\n",
    "verdict['petitioner'] = verdict['petitioner'].astype(int)\n",
    "verdict['respondent'] = verdict.respondent.apply(lambda x: 0 if x == '' else x)\n",
    "verdict['respondent'] = verdict['respondent'].astype(int)\n",
    "verdict['issue'] = verdict.issue.apply(lambda x: 0 if x == '' else x)\n",
    "verdict['issue'] = verdict['issue'].astype(int)\n",
    "verdict['issueArea'] = verdict.issueArea.apply(lambda x: 0 if x == '' else x)\n",
    "verdict['issueArea'] = verdict['issueArea'].astype(int)\n",
    "\n",
    "#join verdict into df\n",
    "train_test_df = pivots_concate.join(verdict.set_index('term_docket'), on='transcript_id')\n",
    "\n",
    "#remove NAs and blanks (these give errors when vectorizing)\n",
    "train_test_df = train_test_df.dropna()\n",
    "#train_test_df = train_test_df[train_test_df['appellant/petitioner_length'] != 0.0] \n",
    "\n",
    "#create train and test split\n",
    "x_orig = train_test_df[['appellant/petitioner', 'appellee/respondent', 'scotus_justice', 'chief',\n",
    "                   'appellant/petitioner_count', 'appellee/respondent_count', 'scotus_justice_count',\n",
    "                   'appellant/petitioner_length', 'appellee/respondent_length','scotus_justice_length',\n",
    "                   'not_a_justice', 'petitioner', 'respondent', 'issue', 'issueArea']]\n",
    "y_orig = train_test_df.partyWinning\n",
    "\n",
    "print \"Data re-shaping and combining done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing done!\n",
      "Accuracy of LR Model 3: 0.6581 (+/- 0.0689)\n",
      "Floor is: 0.6318\n"
     ]
    }
   ],
   "source": [
    "###tfidf vectorizer bag of words using scotus_justice, petitioner, respondent, and additional features\n",
    "##features: chief justice indicator, petitioner code, respondent code, issue code, issue area code\n",
    "\n",
    "#get x_train and x_test features\n",
    "x_train = x_orig[['appellant/petitioner', 'appellee/respondent', 'scotus_justice', 'chief',\n",
    "                   'appellant/petitioner_count', 'appellee/respondent_count', 'scotus_justice_count',\n",
    "                   'appellant/petitioner_length', 'appellee/respondent_length','scotus_justice_length',\n",
    "                   'petitioner', 'respondent', 'issue', 'issueArea']]\n",
    "\n",
    "#count vectorizer\n",
    "stop_words = [\"that\", \"the\", \"court\", \"of\", \"justice\", \"and\", \"please\", \"this\", \"to\"]\n",
    "\n",
    "count_vect_1 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words=stop_words, lowercase = False)\n",
    "count_vect_2 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words=stop_words, lowercase = False)\n",
    "count_vect_3 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words=stop_words, lowercase = False)\n",
    "count_vect_chief = CountVectorizer()\n",
    "\n",
    "print \"Vectorizing done!\"\n",
    "\n",
    "x_train_cv_petitioner_vec = count_vect_1.fit(x_train['appellant/petitioner'])\n",
    "voc1 = count_vect_1.vocabulary_\n",
    "x_train_cv_respondent_vec = count_vect_2.fit(x_train['appellee/respondent'])\n",
    "voc2 = count_vect_2.vocabulary_\n",
    "x_train_cv_scotus_justice_vec = count_vect_3.fit(x_train['scotus_justice'])\n",
    "x_train_chief = count_vect_chief.fit(x_train['chief'])\n",
    "\n",
    "x_train_cv_petitioner = pd.DataFrame(x_train_cv_petitioner_vec.transform(x_train['appellant/petitioner']).todense(),\n",
    "                                        columns = x_train_cv_petitioner_vec.get_feature_names())\n",
    "x_train_cv_respondent = pd.DataFrame(x_train_cv_respondent_vec.transform(x_train['appellee/respondent']).todense(),\n",
    "                                        columns = x_train_cv_respondent_vec.get_feature_names())\n",
    "x_train_cv_scotus_justice = pd.DataFrame(x_train_cv_scotus_justice_vec.transform(x_train['scotus_justice']).todense(),\n",
    "                                        columns = x_train_cv_scotus_justice_vec.get_feature_names())\n",
    "x_train_cv_chief = pd.DataFrame(x_train_chief.transform(x_train['chief']).todense(),\n",
    "                               columns = x_train_chief.get_feature_names())\n",
    "\n",
    "#put features into its own df for concatenate in next step\n",
    "x_train_features = x_train[x_train.columns[4:]]\n",
    "x_train_features = x_train_features.reset_index()\n",
    "\n",
    "#rest y train + test indices, drop 'index' columns, and convert to 1-d matrices\n",
    "y = y_orig.reset_index()\n",
    "y = y.drop(['index'], axis = 1)\n",
    "y = y.as_matrix()\n",
    "y = column_or_1d(y)\n",
    "\n",
    "#change negative numbers into 0\n",
    "x_train_features[x_train_features < 0 ] = 0\n",
    "\n",
    "#concatenate the bow back\n",
    "x = pd.concat([x_train_cv_petitioner, \n",
    "                     x_train_cv_respondent, \n",
    "                     x_train_cv_scotus_justice,\n",
    "                     x_train_cv_chief,\n",
    "                     x_train_features], \n",
    "                     axis = 1)\n",
    "\n",
    "\n",
    "# #random forest\n",
    "#forest_3 = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "#rf_model_3_scores = cross_val_score(forest_3, x, y, cv=20)\n",
    "\n",
    "# #Multinomial Naive Baynes\n",
    "#nb_3 = MultinomialNB(alpha = 0.1)\n",
    "#nb_model_3_scores = cross_val_score(nb_3, x, y, cv=20)\n",
    "\n",
    "# logistic regression\n",
    "lr_model_3 = LogisticRegression(C = 0.82, penalty = \"l1\", n_jobs = -1)\n",
    "lr_model_train_3 = lr_model_3.fit(x, y)\n",
    "lr_model_3_scores = cross_val_score(lr_model_3, x, y, cv=20)\n",
    "\n",
    "#print \"Accuracy of RF Model 3: %0.4f (+/- %0.4f)\" % (rf_model_3_scores.mean(), rf_model_3_scores.std() * 2)\n",
    "#print \"Accuracy of NB Model 3: %0.4f (+/- %0.4f)\" % (nb_model_3_scores.mean(), nb_model_3_scores.std() * 2)\n",
    "print \"Accuracy of LR Model 3: %0.4f (+/- %0.4f)\" % (lr_model_3_scores.mean(), lr_model_3_scores.std() * 2)\n",
    "actual_count = np.unique(y, return_counts=True)[1]\n",
    "num = round(actual_count[1],2)\n",
    "denom  = round(actual_count[0] + actual_count[1],2)\n",
    "print \"Floor is:\", round(np.divide(num, denom), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LR Model 2: 0.6574 (+/- 0.0690)\n",
      "Floor is: 0.6318\n"
     ]
    }
   ],
   "source": [
    "###tfidf vectorizer bag of words using scotus_justice, petitioner, respondent\n",
    "\n",
    "#get x_train and x_test features\n",
    "x_train = x_orig[['appellant/petitioner', 'appellee/respondent', 'scotus_justice',\n",
    "                   'appellant/petitioner_count', 'appellee/respondent_count', 'scotus_justice_count',\n",
    "                   'appellant/petitioner_length', 'appellee/respondent_length','scotus_justice_length']]\n",
    "\n",
    "#count vectorizer\n",
    "count_vect_1 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words='english', lowercase = False)\n",
    "count_vect_2 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words='english', lowercase = False)\n",
    "count_vect_3 = TfidfVectorizer(ngram_range = (3,3), max_features = 2500, stop_words='english', lowercase = False)\n",
    "\n",
    "x_train_cv_petitioner_vec = count_vect_1.fit(x_train['appellant/petitioner'])\n",
    "voc1 = count_vect_1.vocabulary_\n",
    "x_train_cv_respondent_vec = count_vect_2.fit(x_train['appellee/respondent'])\n",
    "voc2 = count_vect_2.vocabulary_\n",
    "x_train_cv_scotus_justice_vec = count_vect_3.fit(x_train['scotus_justice'])\n",
    "\n",
    "x_train_cv_petitioner = pd.DataFrame(x_train_cv_petitioner_vec.transform(x_train['appellant/petitioner']).todense(),\n",
    "                                        columns = x_train_cv_petitioner_vec.get_feature_names())\n",
    "x_train_cv_respondent = pd.DataFrame(x_train_cv_respondent_vec.transform(x_train['appellee/respondent']).todense(),\n",
    "                                        columns = x_train_cv_respondent_vec.get_feature_names())\n",
    "x_train_cv_scotus_justice = pd.DataFrame(x_train_cv_scotus_justice_vec.transform(x_train['scotus_justice']).todense(),\n",
    "                                        columns = x_train_cv_scotus_justice_vec.get_feature_names())\n",
    "\n",
    "#put features into its own df for concatenate in next step\n",
    "x_train_features = x_train[x_train.columns[3:9]]\n",
    "x_train_features = x_train_features.reset_index()\n",
    "\n",
    "#change negative numbers into 0\n",
    "x_train_features[x_train_features < 0 ] = 0\n",
    "\n",
    "#concatenate the bow back\n",
    "x = pd.concat([x_train_cv_petitioner, \n",
    "                     x_train_cv_respondent, \n",
    "                     x_train_cv_scotus_justice,\n",
    "                     x_train_features], \n",
    "                     axis = 1)\n",
    "\n",
    "#rest y train + test indices, drop 'index' columns, and convert to 1-d matrices\n",
    "y = y_orig.reset_index()\n",
    "y = y.drop(['index'], axis = 1)\n",
    "y = y.as_matrix()\n",
    "y = column_or_1d(y)\n",
    "\n",
    "#random forest\n",
    "#forest_2 = RandomForestClassifier(n_estimators = 1000)\n",
    "#rf_model_2_scores = cross_val_score(forest_2, x, y, cv=20)\n",
    "\n",
    "#Multinomial Naive Baynes\n",
    "#nb_2 = MultinomialNB(alpha = 0.1).fit(x_train, y_train)\n",
    "#nb_model_2_scores = cross_val_score(nb_2, x, y, cv=20)\n",
    "\n",
    "# logistic regression\n",
    "lr_model_2 = LogisticRegression(C = 0.57, penalty = \"l1\", n_jobs = -1)\n",
    "lr_model_2_scores = cross_val_score(lr_model_2, x, y, cv=20)\n",
    "\n",
    "#print \"Accuracy of RF Model 2: %0.4f (+/- %0.4f)\" % (rf_model_2_scores.mean(), rf_model_2_scores.std() * 2)\n",
    "#print \"Accuracy of NB Model 2: %0.4f (+/- %0.4f)\" % (nb_model_2_scores.mean(), nb_model_2_scores.std() * 2)\n",
    "print \"Accuracy of LR Model 2: %0.4f (+/- %0.4f)\" % (lr_model_2_scores.mean(), lr_model_2_scores.std() * 2)\n",
    "actual_count = np.unique(y, return_counts=True)[1]\n",
    "num = round(actual_count[1],2)\n",
    "denom  = round(actual_count[0] + actual_count[1],2)\n",
    "print \"Floor is:\", round(np.divide(num, denom), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "# nltk.download('popular')\n",
    "\n",
    "model = Doc2Vec.load('./data_and_etl//D2V_model_3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing start\n",
      "tokenizing complete, infer start\n",
      "infer vectors done, data manipulation start\n",
      "Accuracy of LR Model 2: 0.6509 (+/- 0.0499)\n",
      "Floor is: 0.6318\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "##features: chief justice indicator, petitioner code, respondent code, issue code, issue area code\n",
    "\n",
    "#get x_train and x_test features\n",
    "x_train = x_orig[['appellant/petitioner', 'appellee/respondent', 'scotus_justice',\n",
    "                   'appellant/petitioner_count', 'appellee/respondent_count', 'scotus_justice_count',\n",
    "                   'appellant/petitioner_length', 'appellee/respondent_length','scotus_justice_length']]\n",
    "\n",
    "x_train = x_train.reset_index()\n",
    "x_train = x_train.drop(['index'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "#Embeddings\n",
    "# tokenize function from http://nlpforhackers.io/tf-idf/\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english') + list(punctuation) \n",
    " \n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words]\n",
    "\n",
    "print \"tokenizing start\"\n",
    "\n",
    "x_train_cv_petitioner_tkn =  x_train['appellant/petitioner'].apply(lambda x: tokenize(x))\n",
    "x_train_cv_respondent_tkn  = x_train['appellee/respondent'].apply(lambda x: tokenize(x))\n",
    "x_train_cv_scotus_justice_tkn  = x_train['scotus_justice'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# x_test_cv_petitioner_tkn = x_test['appellant/petitioner'].apply(lambda x: tokenize(x))\n",
    "# x_test_cv_respondent_tkn = x_test['appellee/respondent'].apply(lambda x: tokenize(x))\n",
    "# x_test_cv_scotus_justice_tkn = x_test['scotus_justice'].apply(lambda x: tokenize(x))\n",
    "\n",
    "print \"tokenizing complete, infer start\"\n",
    "\n",
    "x_train_cv_petitioner  = x_train_cv_petitioner_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "x_train_cv_respondent  = x_train_cv_respondent_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "x_train_cv_scotus_justice  = x_train_cv_scotus_justice_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "\n",
    "# x_test_cv_petitioner = x_test_cv_petitioner_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "# x_test_cv_respondent = x_test_cv_respondent_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "# x_test_cv_scotus_justice = x_test_cv_scotus_justice_tkn.apply(lambda x: pd.Series(model.infer_vector(x)))\n",
    "\n",
    "\n",
    "\n",
    "print \"infer vectors done, data manipulation start\"\n",
    "\n",
    "#put features into its own df for concatenate in next step\n",
    "x_train_features = x_train[x_train.columns[3:9]]\n",
    "x_train_features = x_train_features.reset_index()\n",
    "\n",
    "#change negative numbers into 0\n",
    "x_train_features[x_train_features < 0 ] = 0\n",
    "\n",
    "#concatenate the bow back\n",
    "x = pd.concat([x_train_cv_petitioner, \n",
    "                     x_train_cv_respondent, \n",
    "                     x_train_cv_scotus_justice,\n",
    "                     x_train_features], \n",
    "                     axis = 1)\n",
    "\n",
    "#rest y train + test indices, drop 'index' columns, and convert to 1-d matrices\n",
    "y = y_orig.reset_index()\n",
    "y = y.drop(['index'], axis = 1)\n",
    "y = y.as_matrix()\n",
    "y = column_or_1d(y)\n",
    "\n",
    "#random forest\n",
    "#forest_2 = RandomForestClassifier(n_estimators = 1000)\n",
    "#rf_model_2_scores = cross_val_score(forest_2, x, y, cv=20)\n",
    "\n",
    "#Multinomial Naive Baynes\n",
    "#nb_2 = MultinomialNB(alpha = 0.1).fit(x_train, y_train)\n",
    "#nb_model_2_scores = cross_val_score(nb_2, x, y, cv=20)\n",
    "\n",
    "# logistic regression\n",
    "lr_model_2 = LogisticRegression(C = 0.2, penalty = \"l1\", n_jobs = -1)\n",
    "lr_model_2_scores = cross_val_score(lr_model_2, x, y, cv=20)\n",
    "\n",
    "#print \"Accuracy of RF Model 2: %0.4f (+/- %0.4f)\" % (rf_model_2_scores.mean(), rf_model_2_scores.std() * 2)\n",
    "#print \"Accuracy of NB Model 2: %0.4f (+/- %0.4f)\" % (nb_model_2_scores.mean(), nb_model_2_scores.std() * 2)\n",
    "print \"Accuracy of LR Model 2: %0.4f (+/- %0.4f)\" % (lr_model_2_scores.mean(), lr_model_2_scores.std() * 2)\n",
    "actual_count = np.unique(y, return_counts=True)[1]\n",
    "num = round(actual_count[1],2)\n",
    "denom  = round(actual_count[0] + actual_count[1],2)\n",
    "print \"Floor is:\", round(np.divide(num, denom), 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
